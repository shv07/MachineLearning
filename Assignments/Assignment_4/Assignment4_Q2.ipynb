{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from autograd import grad\n",
    "from autograd import elementwise_grad as egrad\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "filname='Real estate valuation data set.xlsx'\n",
    "df=pd.read_excel(filname)\n",
    "data=np.array(df)\n",
    "\n",
    "train_X,test_X,train_Y, test_Y = train_test_split(data[:,1:7],data[:,-1])\n",
    "train_Y=np.array([train_Y]).T\n",
    "test_Y=np.array([test_Y]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(310, 6)\n",
      "(104, 6)\n",
      "(310, 1)\n",
      "(104, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in [train_X,test_X,train_Y, test_Y]:      #verifying  the shapes compatibility\n",
    "    print (i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    X_=[]\n",
    "    for i in range(len(X[0])):\n",
    "        X_.append(X[:,i]/X[:,i].max())\n",
    "    X_=np.array(X_).T\n",
    "    return X_\n",
    "def RMSE(y1,y2):\n",
    "    #calculating RMS\n",
    "    y1=np.transpose(y1)[0]\n",
    "    y2=np.transpose(y2)[0]\n",
    "    rmse=(sum(((y1-y2)**2))/len(y1))**0.5\n",
    "    return rmse\n",
    "def predict(X,theta):\n",
    "    X=np.array(X)\n",
    "    theta=np.array(theta)\n",
    "    X=np.insert(X,0,values=np.ones(len(X)),axis=1)\n",
    "    return np.matmul(X,theta) \n",
    "\n",
    "def normalEquationRidgeRegression(X, y, lmda=0.01):\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    X=np.insert(X,0,values=np.ones(len(X)),axis=1)\n",
    "    X_t=np.transpose(X)\n",
    "    A_=np.matmul(X_t,X)            #=X_t*X\n",
    "    I_=np.diag(np.ones(len(A_)))\n",
    "    I_[0][0]=0                     #=I_\n",
    "    A=A_+lmda*I_                   \n",
    "    theta=0\n",
    "    if np.linalg.det(A)==0:\n",
    "        theta=normalEquationRegression(X[:,1:], y)\n",
    "    else:\n",
    "        A=np.linalg.inv(A)\n",
    "        B=np.matmul(X_t,y)\n",
    "        theta=np.matmul(A,B)\n",
    "    return theta\n",
    "\n",
    "\n",
    "\n",
    "def P_j(X,y, j, theta):   #function to be used in coordinate descent and lasso\n",
    "    tmp_X=np.array([i for i in X])\n",
    "    tmp_theta=np.array([i for i in theta])\n",
    "    np.delete(tmp_theta,j,axis=0)\n",
    "    np.delete(tmp_X,j,axis=1)\n",
    "    y_=np.matmul(tmp_X,tmp_theta)\n",
    "    Pj=0\n",
    "    for index,x in enumerate(tmp_X):\n",
    "        Pj+=x[j]*(y[index][0]-y_[index][0])\n",
    "    return Pj\n",
    "def Z_j(X,j):\n",
    "    X_tmp=X[:,j]\n",
    "    return sum(X_tmp**2)\n",
    "def coodrdinateDescentRegression(X, y, epoch=500):\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    X=np.insert(X,0,values=np.ones(len(X)),axis=1)\n",
    "    theta=np.random.randn(len(X[0]),1)  #random initialization of parameters\n",
    "    for _ in range(epoch):\n",
    "        theta_tmp=np.array([i for i in theta])\n",
    "        for j in range(len(theta)):\n",
    "            Pj=P_j(X,y,j,theta)\n",
    "            Zj=Z_j(X,j)\n",
    "            theta_tmp[j][0]=Pj/Zj\n",
    "        theta=theta_tmp\n",
    "    return theta\n",
    "\n",
    "\n",
    "def coodrdinateDescentLasso(X, y, lmda=0.1, epoch=500):\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    X=np.insert(X,0,values=np.ones(len(X)),axis=1)\n",
    "    theta=np.random.randn(len(X[0]),1)\n",
    "    for _ in range(epoch):\n",
    "        theta_tmp=np.array([i for i in theta])\n",
    "        for j in range(len(X[0])):\n",
    "            Pj=P_j(X,y,j,theta)\n",
    "            if Pj<-lmda/2:\n",
    "                theta_tmp[j][0]=(Pj+lmda/2)/(2*(j+1))\n",
    "            elif Pj>lmda/2:\n",
    "                theta_tmp[j][0]=(Pj-lmda/2)/(2*(j+1))\n",
    "            else:\n",
    "                theta_tmp[j][0]=0\n",
    "        theta=theta_tmp\n",
    "    return theta\n",
    "\n",
    "\n",
    "def grad_eval(x_i, y_i , theta):  #x_i is 1x(d+1) matrix and y_i is a 1x1 vector, it returns the d(error)/d(theta) \n",
    "    theta_new= 2*np.matmul(np.matmul(np.c_[x_i],np.c_[x_i].T),theta)- 2*np.dot(np.c_[x_i], np.array([y_i]))\n",
    "    return theta_new\n",
    "def sgdRegression(X, y, alpha = 0.1, epoch=500):\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    X=np.insert(X,0,values=np.ones(len(X)),axis=1)\n",
    "    theta=np.random.randn(len(X[0]),1)  #random initialization of parameters\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        data=np.insert(X,len(X[0]),values=y.T[0],axis=1)\n",
    "        np.random.shuffle(data)\n",
    "        X_new=data[:,:-1]\n",
    "        y_new=data[:,-1:]\n",
    "        for index,x_i in enumerate(X_new):\n",
    "            y_i=y_new[index]\n",
    "            #print(y_i)\n",
    "            theta=theta-alpha*grad_eval(x_i,y_i,theta)\n",
    "    \n",
    "    return theta\n",
    "    \n",
    "def Error(theta):     #requires globbal declaration of X,y,lmda\n",
    "    global train_X\n",
    "    global train_Y\n",
    "    global lmda\n",
    "    y=train_Y\n",
    "    y_=np.matmul(np.insert(train_X,0,values=np.ones(len(train_X)),axis=1),theta)\n",
    "    return (y-y_)**2+lmda*(sum(abs(theta))[0])\n",
    "\n",
    "def gradientDescentAutogradLasso(X, y, alpha = 0.1, lmda=0.01, epoch=500):\n",
    "    X=np.insert(X,0,values=np.ones(len(X)),axis=1)\n",
    "    theta=np.random.randn(len(X[0]),1)\n",
    "    derivative=egrad(Error)\n",
    "    for i in range(epoch):\n",
    "        #y_=np.matmul(X,theta)\n",
    "        theta=theta-alpha*np.array(derivative(theta))\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.214756118918338, 7.739431723967597]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta=normalEquationRidgeRegression(train_X, train_Y, lmda=0.01)\n",
    "theta\n",
    "[RMSE(train_Y, predict(train_X,theta)), RMSE(test_Y, predict(test_X,theta))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7764322053406734e+26, 1.7814256915499223e+26]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta=coodrdinateDescentLasso(normalize(train_X), train_Y, lmda=1, epoch=10)\n",
    "[RMSE(train_Y, predict(normalize(train_X),theta)), RMSE(test_Y, predict(normalize(test_X),theta))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.7875163954014147e+78, 1.8246922553272375e+78]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta=coodrdinateDescentRegression(normalize(train_X), train_Y, epoch=100)\n",
    "[RMSE(train_Y, predict(normalize(train_X),theta)), RMSE(test_Y, predict(normalize(test_X),theta))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.966905135928979, 9.426698817608205]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta=sgdRegression(normalize(train_X), train_Y, alpha = 0.1, epoch=500)\n",
    "[RMSE(train_Y, predict(normalize(train_X),theta)), RMSE(test_Y, predict(normalize(test_X),theta))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.662350212063898e+84, 9.628347893516075e+84]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmda=0.01\n",
    "theta=gradientDescentAutogradLasso(scaler.fit_transform(train_X), train_Y, alpha = 0.1, lmda=0.01, epoch=10)\n",
    "[RMSE(train_Y, predict(normalize(train_X),theta)), RMSE(test_Y, predict(normalize(test_X),theta))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
